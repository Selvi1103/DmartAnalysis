# DmartAnalysis
## The task is to create a data pipeline using PySpark to integrate and analyze sales data from three different sources: product information, sales transactions, and customer details. The goal is to establish a connection with PySpark, load the datasets, perform data transformations, and answer a set of analytical questions.

## Tasks:

## Task 1: Establish PySpark Connection
 1. Set up a PySpark environment.
 2. Create a connection to read CSV files into PySpark DataFrames.

## Task 2: Load Data into PySpark DataFrames
 1. Load the products.csv, sales.csv, and customer.csv files into separate PySpark DataFrames.

## Task 3: Data Transformation and Cleaning
 1. Perform necessary data cleaning and transformation
 2. Rename columns for consistency if needed.
 3. Handle missing values appropriately.
 4. Ensure data types are correctly set for each column.
 5. Join the DataFrames on relevant keys (Product ID and Customer ID).

## Task 4: Data Analysis and Querying
 1. Formulate 10 analytical questions based on the integrated dataset.
 2. Write PySpark code to answer these questions.

## Task 5 : Run Queries on the Pyspark
